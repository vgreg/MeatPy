{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Specific Symbols (AAPL and SPY)\n",
    "\n",
    "This notebook demonstrates how to create a new ITCH file containing only data for specific symbols of interest.\n",
    "\n",
    "Filtering large ITCH files to specific symbols can significantly reduce file size and processing time for analysis focused on particular securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from meatpy.itch50 import ITCH50MessageReader, ITCH50Writer\n",
    "import time\n",
    "\n",
    "# Define paths\n",
    "data_dir = Path(\"data\")\n",
    "input_file = data_dir / \"S081321-v50.txt.gz\"\n",
    "output_file = data_dir / \"S081321-v50-AAPL-SPY.itch50\"\n",
    "\n",
    "# Symbols we want to extract\n",
    "target_symbols = [\"AAPL\", \"SPY\"]\n",
    "\n",
    "print(f\"Input file: {input_file}\")\n",
    "print(f\"Output file: {output_file}\")\n",
    "print(f\"Target symbols: {target_symbols}\")\n",
    "\n",
    "# Check if input file exists\n",
    "if not input_file.exists():\n",
    "    print(f\"❌ Input file not found: {input_file}\")\n",
    "    print(\"Please place an ITCH 5.0 file (e.g., S081321-v50.txt.gz) in the data/ directory\")\n",
    "else:\n",
    "    print(f\"✅ Input file found: {input_file}\")\n",
    "    input_size_gb = input_file.stat().st_size / (1024**3)\n",
    "    print(f\"Input file size: {input_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_symbols(input_file, output_file, symbols):\n    \\\"\\\"\\\"Extract data for specific symbols from an ITCH file.\n    \n    Args:\n        input_file: Path to input ITCH file\n        output_file: Path to output filtered ITCH file  \n        symbols: List of symbol strings to extract\n        \n    Returns:\n        tuple of (total_messages_processed, filtered_messages_written)\n    \\\"\\\"\\\"\n    # Convert symbols to bytes format (8 bytes, left-padded)\n    symbols_bytes = [symbol.encode().ljust(8) for symbol in symbols]\n    print(f\\\"Looking for symbols: {[s.decode() for s in symbols_bytes]}\\\")\n    \n    message_count = 0\n    filtered_count = 0\n    start_time = time.time()\n    \n    with ITCH50MessageReader(input_file) as reader:\n        with ITCH50Writer(output_file, symbols=symbols) as writer:\n            for message in reader:\n                message_count += 1\n                \n                # Always include system and administrative messages\n                # These provide context needed for proper file interpretation\n                if (message.type in [b'S', b'R', b'H', b'Y', b'L', b'V', b'W', b'K', b'J'] \n                    or not hasattr(message, 'stock')):\n                    writer.process_message(message)\n                    filtered_count += 1\n                    \n                # Include messages for our target symbols\n                elif hasattr(message, 'stock') and message.stock in symbols_bytes:\n                    writer.process_message(message)\n                    filtered_count += 1\n                \n                # Progress indicator\n                if message_count % 1_000_000 == 0:\n                    elapsed = time.time() - start_time\n                    rate = message_count / elapsed if elapsed > 0 else 0\n                    print(f\\\"Processed {message_count:,} messages in {elapsed:.1f}s \\\"\n                          f\\\"({rate:,.0f} msg/s), kept {filtered_count:,} messages \\\"\n                          f\\\"({100*filtered_count/message_count:.1f}%)\\\")\n    \n    elapsed = time.time() - start_time\n    print(f\\\"\\\\n✅ Extraction complete in {elapsed:.1f} seconds\\\")\n    print(f\\\"   Total messages processed: {message_count:,}\\\")\n    print(f\\\"   Messages written: {filtered_count:,}\\\")\n    print(f\\\"   Filtering ratio: {100*filtered_count/message_count:.2f}%\\\")\n    \n    return message_count, filtered_count\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the extraction\n",
    "if input_file.exists():\n",
    "    print(\"🚀 Starting symbol extraction...\\n\")\n",
    "    \n",
    "    total_messages, filtered_messages = extract_symbols(input_file, output_file, target_symbols)\n",
    "    \n",
    "    # Check output file size\n",
    "    if output_file.exists():\n",
    "        output_size_gb = output_file.stat().st_size / (1024**3)\n",
    "        input_size_gb = input_file.stat().st_size / (1024**3)\n",
    "        compression_ratio = output_size_gb / input_size_gb * 100\n",
    "        \n",
    "        print(f\"\\n📁 File size comparison:\")\n",
    "        print(f\"   Input file:  {input_size_gb:.2f} GB\")\n",
    "        print(f\"   Output file: {output_size_gb:.2f} GB\")\n",
    "        print(f\"   Size reduction: {100-compression_ratio:.1f}% smaller\")\n",
    "        print(f\"   Compression ratio: {compression_ratio:.1f}%\")\n",
    "    else:\n",
    "        print(f\"❌ Output file was not created: {output_file}\")\n",
    "else:\n",
    "    print(\"⚠️  Cannot run extraction without input file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify the output by reading a sample of messages\nif output_file.exists():\n    print(\\\"\\\\n🔍 Verifying output file - first 20 messages:\\\")\n    \n    with ITCH50MessageReader(output_file) as reader:\n        for i, message in enumerate(reader):\n            if i >= 20:\n                break\n                \n            msg_type = message.type.decode()\n            \n            if hasattr(message, 'stock'):\n                symbol = message.stock.decode().strip()\n                print(f\\\"  {i+1:2d}. Type {msg_type} - Symbol: {symbol}\\\")\n            else:\n                # System messages don't have symbols\n                msg_descriptions = {\n                    'S': 'System Event',\n                    'R': 'Stock Directory', \n                    'H': 'Trading Halt',\n                    'Y': 'Reg SHO',\n                    'L': 'Market Participant Position'\n                }\n                desc = msg_descriptions.get(msg_type, 'System message')\n                print(f\\\"  {i+1:2d}. Type {msg_type} - {desc}\\\")\n    \n    print(f\\\"\\\\n✅ Output file verification complete\\\")\n    print(f\\\"   File contains filtered data for symbols: {target_symbols}\\\")\n    print(f\\\"   File path: {output_file}\\\")\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "- **System Messages**: Always include system and administrative messages (S, R, H, Y, L, V, W, K, J) as they provide essential context\n",
    "- **Symbol Filtering**: Messages with stock symbols are filtered to include only the target symbols\n",
    "- **Significant Size Reduction**: Filtering to specific symbols can reduce file size by 90%+ depending on how many symbols are in the original file\n",
    "- **Processing Speed**: Smaller filtered files process much faster for subsequent analysis\n",
    "- **Output Format**: The output is a valid ITCH 5.0 file that can be processed by any ITCH-compatible tool\n",
    "\n",
    "## Performance Tips\n",
    "\n",
    "- **Early Filtering**: Filter as early as possible in your data pipeline to reduce downstream processing time\n",
    "- **Multiple Symbols**: You can filter for multiple symbols in a single pass\n",
    "- **Memory Usage**: The ITCH50Writer buffers data efficiently to minimize memory usage during filtering\n",
    "- **Parallel Processing**: For multiple symbol sets, consider running extractions in parallel\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "With your filtered file, you can now:\n",
    "1. Process order book data much faster\n",
    "2. Generate snapshots at regular intervals\n",
    "3. Calculate trading metrics and statistics\n",
    "4. Create visualizations and reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
